# Serverless in the wild论文解读

## 知识导读
### 什么是Serverless
Serverless作用：  
> 把主机管理、操作系统管理、资源分配、扩容，甚至是应用逻辑的全部组件都外包出去，把它们看作某种形式的商品——厂商提供服务，我们掏钱购买。

Serverless的机制:
> 构建或使用一个微服务或微功能来响应一个事件，做到当访问时，调入相关资源开始运行，运行完成后，卸载所有开销，真正做到按需按次计费。这是云计算向纵深发展的一种自然而然的过程。

Serverless的概念：
>是一种构建和管理基于**微服务**架构的完整流程，允许你在**服务**部署级别而不是**服务器**部署级别来管理你的应用部署。它与传统架构的不同之处在于，完全由**第三方管理**，由事件触发，存在于无状态（Stateless）、暂存（可能只存在于一次调用的过程中）计算容器内。构建无服务器应用程序意味着开发者可以专注在产品代码上，而无须管理和操作云端或本地的服务器或运行时。Serverless真正做到了部署应用无需涉及基础设施的建设，自动构建、部署和启动服务。

### 什么是FaaS

Function as a Service，函数即服务。  

FaaS意在无须自行管理服务器系统或自己的服务器应用程序，即可直接运行后端代码。  

FaaS可以取代一些服务处理服务器（可能是物理计算机，但绝对需要运行某种应用程序），这样不仅不需要自行供应服务器，也不需要全时运行应用程序。

### 什么是冷启动
冷启动是指在函数调用链路中的代码下载、启动函数实例容器、运行时初始化、代码初始化等环节。当冷启动完成后，函数实例就绪，后续请求就能直接被执行。

## 内容解读

### 摘要
FaaS的方式越来越受欢迎，云提供商需要尽可能低成本的提供资源，需要深刻理解FaaS。本文介绍Azure Functions整个生产过程的FaaS工作负载。其中大多函数被很少调用，但是被调用的频次很高。本文观察特征后提出了一个实用的资源管理策略，该策略可以显著减少功能冷启动的数量，同时花费的资源比实践状态策略少。

### 介绍
1. FaaS：
>对于用户，用户上传函数代码即可。对于云服务提供商，根据用户上传的函数，在相关事件触发时，提供资源，如运行函数的容器。只根据函数实际运行功能进行计费。
2. 函数执行的速度和资源消耗有三方面：
> 第一个方面： 函数执行需要有代码在内存中，即用户的代码和运行时的库。在内存中表示已经热启动了，函数可以快速启动。  

> 第二个方面：始终保持函数所需资源在内存中对于提供者来说是昂贵的，而且在函数执行时间短且频率低的情况下更加明显。

> 第三个方面：函数的资源需求可能是多样化的，也可能被不同的触发器调用。这对于预测函数的调用规律来降低成本是困难的。
3. 先前工作和现在问题：
> 先前工作聚焦在，运行基准函数评估性能、逆向工程管理资源、实现运行基准函数的原型系统。

> 现在需要的是：从提供者角度描述用户端的FaaS工作负载特征。因此本文描述了 Azure Functions 触发器类型、调用频率和模式以及资源需求。揭露了一些有趣的现象。

4. 管理冷启动策略：
> AWS和Azure使用keep-Alive策略，将资源在函数运行结束后暂存10~20分钟，但是这种策略是低效的，并且忽略了函数调用的规律模式。

> 论文提出的策略：1、用很小的直方图追踪函数调用情况，根据直方图调整keep-alive时间。2、没有明显调用规律的函数，恢复为固定时间的keep-alive策略。3、直方图过小无法捕获，但有明显规律的，用时间序列来研究预热时间。

> 论文作者在Apache OpenWhisk FaaS平台仿真模拟，提及了在Azure Functions中的生产实现。

5. 总结贡献：
> 1. 描述了整个生产FaaS工作负载过程。
> 2. 减少冷启动次数策略
> 3. 仿真和实验结果证明策略的优越性。
> 4. 在Azure Function中的实现。
> 5. 数据集提供

### 背景

1. 摘要：
> 在FaaS中，用户将代码上传到云端，提供商为代码的运行启用句柄(例如URL)。仍然需要选择分配哪些资源、何时分配资源以及保留多长时间，但这些都转移到了云提供商那里。

2. 触发器：
> 本文将Azure的许多触发器分为7类：HTTP、Event、Queue、Timer、 Orchestration、Storage、and others。

> 事件触发器：事件触发器包括Azure事件中心和Azure事件网格，用于离散或串行事件，可以单独处理或批处理。  
> 队列触发器：响应消息队列插入。比如Azure服务总线和Kafka。
> 计时触发器：计时器触发器类似于cron作业，并以预先确定的定期间隔引起函数调用。    
> Orchestration触发器：我们将所有与Azure持久函数相关的触发器组合编排为编排触发器。  
> Storage触发器：响应底层数据的变化，包括Azure Blob Storage和Redis。关于数据库和文件系统。

3. 应用：
> 在Azure Function中，调度和资源分配的单位是应用程序，而不是函数，应用中组织多个函数。

4. 冷启动：
> 当一个函数被触发，但是它的应用程序还没有加载到内存中时，就会发生冷启动调用。当发生这种情况时，平台为应用程序实例化一个“worker”，加载所有所需的runtime和库，并调用该函数。

5. 并发性和弹性：
一个运行实例可以相应可配置数量的并发调用。当工作负载达到峰值，可能发生冷启动并快速进行新的实例化。在完整服务器中只有不到1%的实例会经历这些。

### FaaS的描述

1. 数据收集：
> 我们在2019年7月15日至7月28日期间收集了Azure整个基础设施中所有函数调用的数据。  
收集了四个数据集：  
>1. 调用计数:每个函数，以1分钟为单位;
>2. 每个函数的触发器;
>3. 每个函数的执行时间：记录每个worker间隔30秒的，平均、最小、最大和样本计数。
>4. 每个应用程序的内存使用情况:运行时每5秒采样一次，每个工作程序每分钟采样一次。分配内存和驻留内存的平均值、最小值、最大值和样本计数。

>数据集地址：https://github.com/Azure/AzurePublicDataset.

>数据集限制：
对于调用计数以一分钟为间隔划分，小于1分钟的精度不采用。对于执行时间，保留一组加权百分位数。比如45个样本的平均时间是100ms，则把100ms的分布复制45次。真实分布的逼近情况取决于容器中的样本数量，容器中的样本数量越小越好。同样对内存使用情况也采用加权百分数的方法。


2. 分析数据：  
图1显示了每个应用程序的函数数量的CDF(顶部曲线)。54%的应用只有一个函数，95%的应用有超过10个函数，0.04%超过100。此外，我们看到50%的调用来自最多包含3个函数的应用程序，50%的函数是最多包含6个函数的应用程序的一部分。尽管我们发现应用程序中的函数数量与这些应用程序调用的中位数之间存在微弱的正相关，但应用程序中的函数数量在资源管理中并不是一个有用的信号。

3. 调用规律：
到达间时间变化。为了深入了解应用程序的IAT分布，我们查看每个应用程序的变异系数(CV)。CV(标准差除以平均值)提供了IATs变化性的度量。我们期望定时器触发的函数具有周期性到达，CV为0。人类生成的调用应该大致遵循泊松到达过程，iat呈指数(无记忆)分布。理想情况下，这将产生1的CV。cv大于1表明存在显著的变化性。

4. 函数执行次数：  
函数执行时间，不包括冷启动时间。图7显示了2019年7月15日所有函数执行的平均、最小和最大执行时间分布。其他日子的分布情况类似。该图还显示了对平均值分布的非常好的对数正态拟合(通过MLE)，对数平均值为-0.38和2.36。  
我们观察到，50%的函数的平均执行时间小于15秒，50%的函数的最大执行时间小于~ 3s;90%的函数最长耗时60秒，96%的函数平均耗时小于60秒。其主要含义是，**函数执行时间与主要提供程序报告的冷启动时间处于同一数量级**。这使得避免和/或优化冷启动对于FaaS产品的整体性能至关重要。  
管理冷启动的工作负载的一个重要方面是空闲时间(IT)，空闲时间定义为函数执行结束和下一次调用之间的时间。IT与IAT和执行时间有关。对于大多数应用程序，平均执行时间比平均IAT至少小2个数量级。IT和IAT分布确实非常相似。

5. 内存需求：
查看最大分配内存的分布，90%的应用程序消耗的内存从未超过400MB, 50%的应用程序最多分配170MB。总的来说，在前90%的应用程序中存在4倍的差异，这意味着内存在FaaS的预热、分配和保持活动决策中是一个重要因素。  
我们发现调用频率和内存分配之间、内存分配和函数执行时间之间没有很强的相关性。